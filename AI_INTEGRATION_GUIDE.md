# ü§ñ Guide d'Int√©gration IA - Lisa

**Date**: 6 Novembre 2025  
**Status**: ‚úÖ Pr√™t √† l'emploi

---

## üéØ Ce Qui a √ât√© Int√©gr√©

### 1. Service IA Unifi√© (`aiService.ts`)

Service multi-provider avec support streaming :

#### Providers Support√©s

| Provider | Mod√®les | Streaming | Vision |
|----------|---------|-----------|--------|
| **OpenAI** | GPT-4o, GPT-4o-mini, GPT-4 | ‚úÖ | ‚úÖ |
| **Anthropic** | Claude 3.5 Sonnet, Claude 3 Opus | ‚úÖ | ‚úÖ |
| **Local** | Ollama, LM Studio, etc. | ‚úÖ | ‚ùå |

#### Fonctionnalit√©s

- ‚úÖ Streaming temps r√©el (Server-Sent Events)
- ‚úÖ Support images (vision multi-modale)
- ‚úÖ Gestion erreurs robuste
- ‚úÖ Configuration dynamique
- ‚úÖ Fallback providers

### 2. Hook React (`useAIChat.ts`)

Hook pour int√©gration facile dans les composants :

```typescript
const { 
  sendMessage,        // Envoyer un message
  cancelGeneration,   // Annuler g√©n√©ration
  regenerateLastResponse, // R√©g√©n√©rer
  isLoading,          // √âtat chargement
  isStreaming         // √âtat streaming
} = useAIChat(conversationId, {
  provider: 'openai',
  model: 'gpt-4o-mini',
  temperature: 0.7,
  systemPrompt: 'Tu es Lisa, un assistant IA...'
});
```

### 3. Composant Upload d'Images (`ImageUpload.tsx`)

- ‚úÖ Drag & drop
- ‚úÖ Preview avec suppression
- ‚úÖ Conversion Base64 automatique
- ‚úÖ Limite de taille (5MB)
- ‚úÖ Validation format

---

## ‚öôÔ∏è Configuration

### 1. Cl√©s API

Ajouter dans `.env` :

```env
# OpenAI
VITE_OPENAI_API_KEY=sk-...

# Anthropic (Claude)
VITE_ANTHROPIC_API_KEY=sk-ant-...

# Optionnel: API locale
# Pas besoin de cl√© si utilisation Ollama/LM Studio
```

### 2. Obtenir les Cl√©s

#### OpenAI
1. Aller sur [platform.openai.com](https://platform.openai.com/)
2. Cr√©er un compte / se connecter
3. Aller dans "API Keys"
4. Cr√©er une nouvelle cl√©
5. Ajouter des cr√©dits (minimum $5)

**Mod√®les recommand√©s** :
- `gpt-4o-mini` : Rapide et √©conomique (~$0.15/M tokens)
- `gpt-4o` : Plus puissant (~$2.50/M tokens)
- `gpt-4` : Le plus intelligent (~$30/M tokens)

#### Anthropic (Claude)
1. Aller sur [console.anthropic.com](https://console.anthropic.com/)
2. Cr√©er un compte
3. Aller dans "API Keys"
4. Cr√©er une nouvelle cl√©
5. Ajouter des cr√©dits

**Mod√®les recommand√©s** :
- `claude-3-5-sonnet-20241022` : Meilleur rapport qualit√©/prix
- `claude-3-opus-latest` : Le plus puissant

#### Local (Gratuit)

**Option 1: Ollama**
```bash
# Installer Ollama
# https://ollama.ai

# T√©l√©charger un mod√®le
ollama pull llama2
ollama pull mistral

# L'API sera sur http://localhost:11434
```

**Option 2: LM Studio**
1. T√©l√©charger [LM Studio](https://lmstudio.ai/)
2. T√©l√©charger un mod√®le (ex: Llama 2)
3. D√©marrer le serveur local
4. Configurer baseURL dans le code

---

## üöÄ Utilisation

### Exemple Complet

```typescript
import { useAIChat } from '../hooks/useAIChat';
import { ImageUpload } from '../components/chat/ImageUpload';

function MyChatComponent() {
  const [currentImage, setCurrentImage] = useState<string>();
  
  const { 
    sendMessage, 
    isLoading, 
    isStreaming 
  } = useAIChat(conversationId, {
    provider: 'openai', // ou 'anthropic', 'local'
    model: 'gpt-4o-mini',
    temperature: 0.7,
    systemPrompt: 'Tu es Lisa, un assistant IA fran√ßais...'
  });

  const handleSend = async (message: string) => {
    await sendMessage(message, currentImage);
    setCurrentImage(undefined);
  };

  return (
    <div>
      <ImageUpload
        currentImage={currentImage}
        onImageSelect={setCurrentImage}
        onImageRemove={() => setCurrentImage(undefined)}
      />
      
      <input 
        onKeyPress={(e) => {
          if (e.key === 'Enter' && !isLoading) {
            handleSend(e.currentTarget.value);
          }
        }}
      />
      
      {isStreaming && <TypingIndicator />}
    </div>
  );
}
```

### Exemple avec Vision (Images)

```typescript
// Envoyer un message avec une image
const base64Image = '...'; // Base64 ou URL
await sendMessage('D√©cris cette image', base64Image);
```

### Changer de Provider

```typescript
// OpenAI
const chat = useAIChat(id, { 
  provider: 'openai', 
  model: 'gpt-4o-mini' 
});

// Anthropic (Claude)
const chat = useAIChat(id, { 
  provider: 'anthropic', 
  model: 'claude-3-5-sonnet-20241022' 
});

// Local (Ollama)
const chat = useAIChat(id, { 
  provider: 'local', 
  model: 'llama2',
  baseURL: 'http://localhost:11434'
});
```

### Annuler une G√©n√©ration

```typescript
const { cancelGeneration } = useAIChat(conversationId);

// Dans un bouton Stop
<button onClick={cancelGeneration}>
  Arr√™ter la g√©n√©ration
</button>
```

### R√©g√©n√©rer une R√©ponse

```typescript
const { regenerateLastResponse } = useAIChat(conversationId);

// Dans un bouton R√©g√©n√©rer
<button onClick={regenerateLastResponse}>
  R√©g√©n√©rer
</button>
```

---

## üìä Streaming en Temps R√©el

Le streaming affiche les tokens au fur et √† mesure :

```typescript
// Le hook g√®re automatiquement le streaming
const { sendMessage, isStreaming } = useAIChat(conversationId);

// Envoyer un message = streaming automatique
await sendMessage('Raconte-moi une histoire');

// isStreaming = true pendant la g√©n√©ration
// Le message s'affiche token par token dans la conversation
```

---

## üé® Int√©gration ChatInput

Pour int√©grer au `ChatInput` existant :

```typescript
// Dans ChatInput.tsx
import { useAIChat } from '../../hooks/useAIChat';
import { ImageUpload } from './ImageUpload';

function ChatInput({ conversationId }: Props) {
  const [input, setInput] = useState('');
  const [image, setImage] = useState<string>();
  
  const { sendMessage, isLoading } = useAIChat(conversationId, {
    provider: 'openai',
    model: 'gpt-4o-mini',
    systemPrompt: 'Tu es Lisa, assistante IA fran√ßaise...'
  });

  const handleSend = async () => {
    if (!input.trim() || isLoading) return;
    
    await sendMessage(input, image);
    setInput('');
    setImage(undefined);
  };

  return (
    <div className="chat-input">
      <ImageUpload 
        currentImage={image}
        onImageSelect={setImage}
        onImageRemove={() => setImage(undefined)}
      />
      
      <textarea 
        value={input}
        onChange={(e) => setInput(e.target.value)}
        onKeyPress={(e) => {
          if (e.key === 'Enter' && !e.shiftKey) {
            e.preventDefault();
            handleSend();
          }
        }}
      />
      
      <button onClick={handleSend} disabled={isLoading}>
        {isLoading ? 'Envoi...' : 'Envoyer'}
      </button>
    </div>
  );
}
```

---

## üí∞ Co√ªts Estim√©s

### OpenAI (gpt-4o-mini)

- **Prix**: ~$0.15 / 1M tokens input, ~$0.60 / 1M tokens output
- **Conversation moyenne**: ~10¬¢ pour 100 messages
- **Recommand√© pour**: Usage quotidien

### Anthropic (Claude 3.5 Sonnet)

- **Prix**: ~$3 / 1M tokens input, ~$15 / 1M tokens output
- **Conversation moyenne**: ~$2 pour 100 messages
- **Recommand√© pour**: T√¢ches complexes

### Local (Gratuit)

- **Prix**: 0‚Ç¨
- **Requis**: GPU recommand√© (8GB+ VRAM)
- **Recommand√© pour**: Confidentialit√©, dev, tests

---

## üîí S√©curit√©

### ‚ö†Ô∏è Important

- **NE JAMAIS** commit les cl√©s API dans Git
- Les cl√©s doivent √™tre dans `.env` (d√©j√† dans `.gitignore`)
- En production, utiliser des variables d'environnement

### V√©rification

```bash
# V√©rifier que .env est ignor√©
git status .env
# Doit afficher: nothing to commit
```

---

## üêõ D√©pannage

### Erreur: "VITE_OPENAI_API_KEY non configur√©e"

```bash
# 1. Cr√©er/√©diter .env √† la racine du projet
echo "VITE_OPENAI_API_KEY=sk-..." >> .env

# 2. Red√©marrer le serveur de dev
Ctrl+C
npm run dev
```

### Erreur: "Rate limit exceeded"

Vous avez d√©pass√© la limite de requ√™tes. Attendez quelques minutes ou:
- Ajouter des cr√©dits √† votre compte
- Passer √† un plan payant
- R√©duire le nombre de requ√™tes

### Erreur: "Invalid API key"

- V√©rifier que la cl√© commence par `sk-` (OpenAI) ou `sk-ant-` (Anthropic)
- V√©rifier que la cl√© est active sur le dashboard
- Recr√©er une nouvelle cl√© si n√©cessaire

### Pas de streaming

V√©rifier que:
- Le provider supporte le streaming (OpenAI, Anthropic: oui; Local: d√©pend)
- La connexion r√©seau est stable
- Le mod√®le supporte le streaming

---

## üìù Prochaines √âtapes

### Maintenant

1. ‚úÖ Configurer les cl√©s API dans `.env`
2. ‚úÖ Tester avec un provider (OpenAI recommand√©)
3. ‚úÖ Int√©grer au `ChatInput`

### Bient√¥t

- [ ] Ajouter bouton "Stop generation"
- [ ] Ajouter bouton "Regenerate"
- [ ] Support audio (Text-to-Speech)
- [ ] Support artifacts (code, graphs)
- [ ] Fine-tuning sur donn√©es utilisateur

---

## üéâ R√©sultat

Vous avez maintenant :
- ‚úÖ Service IA multi-provider
- ‚úÖ Streaming temps r√©el
- ‚úÖ Support images/vision
- ‚úÖ Hook React pr√™t √† l'emploi
- ‚úÖ Upload images int√©gr√©
- ‚úÖ Gestion erreurs robuste

**Lisa peut maintenant discuter intelligemment !** üöÄ

---

**Document cr√©√© par**: Cascade AI  
**Date**: 6 Novembre 2025, 08:30
